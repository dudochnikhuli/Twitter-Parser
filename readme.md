# Phantombuster Web Scraper

Инструмент для автоматизированного сбора данных из таблиц на сайте Phantombuster. Скрипт автоматически авторизуется на сайте, извлекает данные из всех доступных таблиц и сохраняет их в CSV-файлы.

# Инструкция по установке и настройке ChromeDriver

Эта инструкция поможет вам правильно установить и настроить ChromeDriver для работы скрипта Phantombuster Scraper.

## 1. Определите версию вашего Chrome браузера

1. Откройте Chrome
2. В адресной строке введите: `chrome://version/`
3. Запишите первые цифры версии (например, из версии 123.0.6312.87 вам нужно запомнить 123)

## 2. Скачайте соответствующий ChromeDriver

1. Перейдите на [сайт загрузки ChromeDriver](https://chromedriver.chromium.org/downloads)
2. Выберите версию, соответствующую вашему Chrome (например, ChromeDriver 123.x.xxxx.xx для Chrome 123)
3. Скачайте ZIP-архив для вашей операционной системы (chromedriver_win32.zip для Windows)

## 3. Установите ChromeDriver в правильное место

1. Распакуйте скачанный ZIP-архив
2. Поместите файл `chromedriver.exe` (Windows) или `chromedriver` (Linux/Mac) в одну из следующих директорий:
   - В корневую папку проекта (где находится parser.py)
   - В подпапку `webdriver` в корневой папке проекта (создайте её, если её нет)

## 4. Структура папок проекта

После установки структура вашего проекта должна выглядеть примерно так:

```
phantombuster-scraper/
├── parser.py                # Основной скрипт для парсинга (ОБНОВЛЁННЫЙ)
├── chromedriver.exe         # Вариант 1: ChromeDriver в корневой папке
├── webdriver/               # Вариант 2: ChromeDriver в подпапке
│   └── chromedriver.exe     
├── Cookies.json             # Файл с cookies для авторизации
├── updates.md               # Обновлённый журнал изменений
└── Results/                 # Папка для сохранения результатов
```

## 5. Проверка работоспособности

После установки ChromeDriver, запустите скрипт:

```bash
python parser.py
```

Если всё настроено правильно, вы должны увидеть сообщение:
```
Найден ChromeDriver: [путь_к_вашему_chromedriver]
ChromeDriver успешно инициализирован
```

## Возможные проблемы и их решения

### Ошибка "ChromeDriver не найден"
- Убедитесь, что файл chromedriver.exe находится в одной из указанных выше директорий
- Проверьте права доступа к файлу (особенно в Linux/Mac)

### Ошибка несовместимости версий
- Убедитесь, что версия ChromeDriver соответствует версии вашего Chrome
- Если версии не совпадают, скачайте правильную версию ChromeDriver

### Ошибка при запуске ChromeDriver
- Попробуйте запустить chromedriver.exe напрямую из командной строки для проверки
- В Windows может потребоваться разрешить запуск в настройках безопасности

### Chrome не запускается
- Убедитесь, что путь к chrome.exe указан правильно (особенно если у вас нестандартная установка)
- Попробуйте указать полный путь к браузеру в опциях запуска

## Технические требования

- Python 3.11.9 (рекомендуется)
- Google Chrome
- Доступ к аккаунту Phantombuster

## Установка

1. Клонируйте репозиторий:
```bash
git clone https://github.com/your-username/phantombuster-scraper.git
cd phantombuster-scraper
```

2. Создайте и активируйте виртуальное окружение:
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/MacOS
python -m venv venv
source venv/bin/activate
```

3. Установите зависимости:
```bash
pip install -r requirements.txt
```

## Настройка

### Настройка авторизации

1. **Подготовка файла cookies**:
   
   Для доступа к закрытым разделам Phantombuster необходимо предоставить cookies авторизованной сессии:

   a. Войдите в свой аккаунт Phantombuster через браузер
   
   b. Используйте расширение для экспорта cookies (например, "EditThisCookie" для Chrome)
   
   c. Экспортируйте cookies в JSON формате
   
   d. Сохраните файл как `Cookies.json` в корневой директории проекта

2. **Проверка URL**:
   
   Убедитесь, что URL в скрипте соответствует нужному разделу Phantombuster:
   ```python
   url = "https://phantombuster.com/7912167802097990/phantoms/5388867849466815/console"
   ```

### Настройка параметров скрапинга

При необходимости можно настроить следующие параметры в файле `main.py`:

- `next_button_xpath` - XPath кнопки перехода на следующую страницу
- Количество отображаемых строк в функции `select_page_size()`
- Время ожидания после загрузки страницы

## Использование

1. Запустите скрипт:
```bash
python main.py
```

2. Скрипт автоматически выполнит следующие действия:
   - Откроет браузер Chrome
   - Перейдет на указанный URL
   - Загрузит cookies для авторизации
   - Выберет отображение 30 строк на странице
   - Последовательно обработает все страницы с таблицами
   - Сохранит каждую таблицу в отдельный CSV файл в папке `Results/`
   - Объединит все таблицы в один файл `Results.csv`

## Структура проекта

```
phantombuster-scraper/
├── main.py                # Основной скрипт для парсинга
├── Cookies.json           # Файл с cookies для авторизации
├── requirements.txt       # Зависимости проекта
├── README.md              # Руководство по проекту
├── Updates.md             # Журнал обновлений
└── Results/               # Папка для сохранения результатов
    ├── 1.csv              # Таблица с первой страницы
    ├── 2.csv              # Таблица со второй страницы
    └── ...
```

## Решение проблем

### 1. Ошибка "WebDriver not found"
- Убедитесь, что Chrome установлен в системе
- Попробуйте обновить webdriver-manager: `pip install --upgrade webdriver-manager`

### 2. Проблемы с авторизацией
- Проверьте актуальность файла Cookies.json (cookies имеют срок действия)
- Экспортируйте cookies заново

### 3. Таблица не парсится корректно
- Проверьте XPath селекторы в функции `parse_table()`
- Добавьте время ожидания для полной загрузки таблицы

### 4. Кнопка "далее" не найдена
- Проверьте XPath кнопки `next_button_xpath`
- Увеличьте время ожидания в WebDriverWait

## Расширение функциональности

### Добавление прокси

Для использования прокси измените настройку драйвера в функции `setup_driver()`:

```python
def setup_driver():
    chrome_options = Options()
    # Добавляем прокси
    chrome_options.add_argument('--proxy-server=http://your-proxy-address:port')
    # ... остальной код
```

### Запуск в режиме headless

Для запуска без визуального интерфейса:

```python
chrome_options.add_argument("--headless")
```

### Сохранение в другие форматы

Для сохранения в Excel формат:

```python
# Импортируйте дополнительные библиотеки
from openpyxl import Workbook

# Изменение в main()
combined_df.to_excel("Results.xlsx", index=False)
```

## Лицензия

MIT